{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Chessboard pattern size (inner corners in width and height)\n",
    "pattern_size = (6, 8)\n",
    "\n",
    "# Real-world size of a square on the chessboard (e.g., in meters or millimeters)\n",
    "square_size = 2.5\n",
    "# Prepare object points\n",
    "objp = np.zeros((pattern_size[0] * pattern_size[1], 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:pattern_size[1], 0:pattern_size[0]].T.reshape(-1, 2) \n",
    "\n",
    "# Arrays to store object points and image points\n",
    "objpoints = []         # 3D points in real-world space\n",
    "imgpoints_left = []    # 2D points in left image plane\n",
    "imgpoints_right = []   # 2D points in right image plane\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Images:\n",
      "['Left Camera Chess/chess8l.jpeg', 'Left Camera Chess/chess10l.jpeg', 'Left Camera Chess/chess9l.jpeg', 'Left Camera Chess/chess5l.jpeg', 'Left Camera Chess/chess7l.jpeg', 'Left Camera Chess/chess3l.jpeg', 'Left Camera Chess/chess1l.jpeg', 'Left Camera Chess/chess6l.jpeg', 'Left Camera Chess/chess4l.jpeg', 'Left Camera Chess/chess2l.jpeg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# Path to the folder containing the images\n",
    "folder_path = \"Left Camera Chess\"\n",
    "\n",
    "# List to store left image file paths\n",
    "left_images = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if \"l\" in filename.lower():  # Check if \"left\" is in the filename\n",
    "        left_images.append(os.path.join(folder_path, filename))\n",
    "\n",
    "# Print the list of left images\n",
    "print(\"Left Images:\")\n",
    "print(left_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right Images:\n",
      "['Right Camera Chess/chess9r.jpeg', 'Right Camera Chess/chess10r.jpeg', 'Right Camera Chess/chess8r.jpeg', 'Right Camera Chess/chess2r.jpeg', 'Right Camera Chess/chess4r.jpeg', 'Right Camera Chess/chess6r.jpeg', 'Right Camera Chess/chess1r.jpeg', 'Right Camera Chess/chess3r.jpeg', 'Right Camera Chess/chess7r.jpeg', 'Right Camera Chess/chess5r.jpeg']\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"Right Camera Chess\"\n",
    "\n",
    "# List to store left image file paths\n",
    "right_images = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if \"r\" in filename.lower():  # Check if \"left\" is in the filename\n",
    "        right_images.append(os.path.join(folder_path, filename))\n",
    "\n",
    "# Print the list of left images\n",
    "print(\"Right Images:\")\n",
    "print(right_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for left_path, right_path in zip(left_images, right_images):\n",
    "    img_left = cv2.imread(left_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img_right = cv2.imread(right_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Detect chessboard corners in both images\n",
    "    ret_left, corners_left = cv2.findChessboardCorners(img_left, pattern_size)\n",
    "    ret_right, corners_right = cv2.findChessboardCorners(img_right, pattern_size)\n",
    "\n",
    "    if ret_left and ret_right:\n",
    "        # Refine corner detection\n",
    "        corners_left = cv2.cornerSubPix(img_left, corners_left, (11, 11), (-1, -1), \n",
    "                                        criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "        corners_right = cv2.cornerSubPix(img_right, corners_right, (11, 11), (-1, -1), \n",
    "                                         criteria=(cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "\n",
    "        # Append points\n",
    "    objpoints.append(objp)\n",
    "    imgpoints_left.append(corners_left)\n",
    "    imgpoints_right.append(corners_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Camera Matrix:\n",
      " [[3.55919524e+03 0.00000000e+00 5.36908639e+02]\n",
      " [0.00000000e+00 3.63513511e+03 9.29793444e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Right Camera Matrix:\n",
      " [[3.93855310e+03 0.00000000e+00 4.26410801e+02]\n",
      " [0.00000000e+00 6.01968364e+03 6.42043524e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Calibrate the left camera\n",
    "ret_left, mtx_left, dist_left, rvecs_left, tvecs_left = cv2.calibrateCamera(\n",
    "    objpoints, imgpoints_left, img_left.shape[::-1], None, None\n",
    ")\n",
    "\n",
    "# Calibrate the right camera\n",
    "ret_right, mtx_right, dist_right, rvecs_right, tvecs_right = cv2.calibrateCamera(\n",
    "    objpoints, imgpoints_right, img_right.shape[::-1], None, None\n",
    ")\n",
    "\n",
    "# Print intrinsics for verification\n",
    "print(\"Left Camera Matrix:\\n\", mtx_left)\n",
    "print(\"Right Camera Matrix:\\n\", mtx_right)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation Matrix (R):\n",
      " [[ 0.98164755 -0.18962039 -0.02030243]\n",
      " [ 0.19051132  0.97029521  0.14910612]\n",
      " [-0.00857421 -0.1502375   0.98861275]]\n",
      "Translation Vector (T):\n",
      " [[-162.28105836]\n",
      " [  12.54724592]\n",
      " [5750.75871017]]\n"
     ]
    }
   ],
   "source": [
    "# Stereo calibration\n",
    "flags = cv2.CALIB_FIX_INTRINSIC  # Use this if intrinsics are precomputed\n",
    "ret, mtx_left, dist_left, mtx_right, dist_right, R, T, E, F = cv2.stereoCalibrate(\n",
    "    objpoints, imgpoints_left, imgpoints_right,\n",
    "    mtx_left, dist_left, mtx_right, dist_right,\n",
    "    img_left.shape[::-1], flags=flags\n",
    ")\n",
    "\n",
    "# Print extrinsic parameters\n",
    "print(\"Rotation Matrix (R):\\n\", R)\n",
    "print(\"Translation Vector (T):\\n\", T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  0.00000000e+00  0.00000000e+00  3.15978279e+01]\n",
      " [ 0.00000000e+00  1.00000000e+00  0.00000000e+00 -1.42673712e+04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  3.74887417e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.73820491e-04 -0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Stereo rectification\n",
    "R1, R2, P1, P2, Q, _, _ = cv2.stereoRectify(\n",
    "    mtx_left, dist_left, mtx_right, dist_right, img_left.shape[::-1], R, T\n",
    ")\n",
    "\n",
    "# Save parameters for future use\n",
    "np.savez(\"stereo_calibration.npz\", \n",
    "         mtx_left=mtx_left, dist_left=dist_left, \n",
    "         mtx_right=mtx_right, dist_right=dist_right, \n",
    "         R=R, T=T, Q=Q)\n",
    "\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00000000e+00  0.00000000e+00  0.00000000e+00  3.15978279e+01]\n",
      " [ 0.00000000e+00  1.00000000e+00  0.00000000e+00 -1.42673712e+04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  3.74887417e+03]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.73820491e-04 -0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "calibration_data = np.load(\"stereo_calibration.npz\")\n",
    "mtx_left = calibration_data['mtx_left']\n",
    "dist_left = calibration_data['dist_left']\n",
    "mtx_right = calibration_data['mtx_right']\n",
    "dist_right = calibration_data['dist_right']\n",
    "R = calibration_data['R']\n",
    "T = calibration_data['T']\n",
    "Q = calibration_data['Q']\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1196 13785]\n",
      "  [-1194 13782]\n",
      "  [-1191 13780]\n",
      "  ...\n",
      "  [  891 14172]\n",
      "  [  893 14175]\n",
      "  [  896 14178]]\n",
      "\n",
      " [[-1197 13792]\n",
      "  [-1195 13790]\n",
      "  [-1192 13787]\n",
      "  ...\n",
      "  [  891 14179]\n",
      "  [  894 14183]\n",
      "  [  896 14186]]\n",
      "\n",
      " [[-1198 13800]\n",
      "  [-1195 13797]\n",
      "  [-1193 13795]\n",
      "  ...\n",
      "  [  892 14187]\n",
      "  [  894 14191]\n",
      "  [  897 14194]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-3206 32767]\n",
      "  [-3200 32767]\n",
      "  [-3193 32767]\n",
      "  ...\n",
      "  [ 2099 32767]\n",
      "  [ 2106 32767]\n",
      "  [ 2112 32767]]\n",
      "\n",
      " [[-3208 32767]\n",
      "  [-3202 32767]\n",
      "  [-3195 32767]\n",
      "  ...\n",
      "  [ 2100 32767]\n",
      "  [ 2107 32767]\n",
      "  [ 2113 32767]]\n",
      "\n",
      " [[-3210 32767]\n",
      "  [-3204 32767]\n",
      "  [-3197 32767]\n",
      "  ...\n",
      "  [ 2102 32767]\n",
      "  [ 2108 32767]\n",
      "  [ 2115 32767]]]\n",
      "[[ 352  916  456 ...  167  599  998]\n",
      " [ 711  251  815 ...  948  323  755]\n",
      " [  47  611  151 ...  705  112  512]\n",
      " ...\n",
      " [ 548  306   33 ...  373  676   52]\n",
      " [  37  820  546 ...  318  654   30]\n",
      " [ 550  309   68 ...  296  664 1000]]\n",
      "[[212 212 212 ... 196 196 196]\n",
      " [212 212 212 ... 196 196 196]\n",
      " [212 212 212 ... 196 196 196]\n",
      " ...\n",
      " [201 200 199 ... 234 234 234]\n",
      " [201 201 200 ... 234 234 234]\n",
      " [202 201 201 ... 234 234 234]]\n",
      "[[ 75  75  74 ... 190 190 190]\n",
      " [ 75  75  74 ... 190 190 190]\n",
      " [ 75  75  75 ... 190 190 190]\n",
      " ...\n",
      " [ 65  65  65 ... 199 200 200]\n",
      " [ 65  65  65 ... 199 200 200]\n",
      " [ 65  65  65 ... 199 200 200]]\n"
     ]
    }
   ],
   "source": [
    "# Load a pair of scene images\n",
    "img_left = cv2.imread(\"Left Camera Scene/scene1l.jpeg\", cv2.IMREAD_GRAYSCALE)\n",
    "img_right = cv2.imread(\"Right Camera Scene/scene1r.jpeg\", cv2.IMREAD_GRAYSCALE)\n",
    "# print(img_left)\n",
    "# print(img_right)\n",
    "\n",
    "# Stereo rectification\n",
    "image_size = img_left.shape[::-1]\n",
    "R1, R2, P1, P2, Q, _, _ = cv2.stereoRectify(\n",
    "    mtx_left, dist_left, mtx_right, dist_right, image_size, R, T\n",
    ")\n",
    "\n",
    "# Compute rectification maps\n",
    "map1_left, map2_left = cv2.initUndistortRectifyMap(\n",
    "    mtx_left, dist_left, R1, P1, image_size, cv2.CV_16SC2\n",
    ")\n",
    "map1_right, map2_right = cv2.initUndistortRectifyMap(\n",
    "    mtx_right, dist_right, R2, P2, image_size, cv2.CV_16SC2\n",
    ")\n",
    "print(map1_right)\n",
    "print(map2_right)\n",
    "print(img_right)\n",
    "# Rectify images\n",
    "rectified_left = cv2.remap(img_left, map1_left, map2_left, cv2.INTER_LINEAR)\n",
    "rectified_right = cv2.remap(img_right, map1_right, map2_right, cv2.INTER_LINEAR)\n",
    "print(rectified_left)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " ...\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "stereo = cv2.StereoBM_create(numDisparities=16*3, blockSize=15)\n",
    "# Compute disparity map\n",
    "disparity = stereo.compute(rectified_left, rectified_right).astype(np.float32) / 16.0\n",
    "print(disparity)\n",
    "\n",
    "# Normalize the disparity map for visualization\n",
    "disparity_normalized = cv2.normalize(disparity, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject disparity to 3D points\n",
    "points_3D = cv2.reprojectImageTo3D(disparity, Q)\n",
    "\n",
    "# Mask invalid points\n",
    "mask = disparity > disparity.min()\n",
    "points_3D = points_3D[mask]\n",
    "\n",
    "# Get the color information from the left image\n",
    "colors = cv2.cvtColor(cv2.imread(\"Left Camera Scene/scene1l.jpeg\"), cv2.COLOR_BGR2RGB)[mask]\n",
    "\n",
    "# Save as a PLY file for 3D visualization\n",
    "def save_point_cloud(filename, points, colors):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(\"ply\\nformat ascii 1.0\\n\")\n",
    "        f.write(f\"element vertex {len(points)}\\n\")\n",
    "        f.write(\"property float x\\nproperty float y\\nproperty float z\\n\")\n",
    "        f.write(\"property uchar red\\nproperty uchar green\\nproperty uchar blue\\n\")\n",
    "        f.write(\"end_header\\n\")\n",
    "        for p, c in zip(points, colors):\n",
    "            f.write(f\"{p[0]} {p[1]} {p[2]} {c[0]} {c[1]} {c[2]}\\n\")\n",
    "\n",
    "save_point_cloud(\"scene_reconstruction.ply\", points_3D, colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[Open3D WARNING] Read PLY failed: number of vertex <= 0.\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] The number of points is 0 when creating axis-aligned bounding box.\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(\"scene_reconstruction.ply\")\n",
    "\n",
    "# Visualize the point cloud\n",
    "o3d.visualization.draw_geometries([pcd])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
